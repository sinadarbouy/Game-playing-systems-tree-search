{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo Tree Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math  \n",
    "import random\n",
    "import time\n",
    "import operator\n",
    "from colorama import Fore, Style\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, state, parent):\n",
    "        self.N = 0 #Total number of visits\n",
    "        self.Q = 0 #Total accumulated reward\n",
    "        self.is_end_state = state.is_end_state()\n",
    "        self.is_expanded_completly = self.is_end_state\n",
    "        self.state = state \n",
    "        self.parent = parent\n",
    "        self.children = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$UCT = \\frac{Q}{N} + c\\sqrt{\\frac{\\log{N}}{N}}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class monte_carlo_tree_search():\n",
    "    def __init__(self, c = 2):\n",
    "        self.c = c   # how much to explore\n",
    " \n",
    "    def rollout_policy(self, state):## randomly pick\n",
    "        while state.is_end_state()!= True:\n",
    "            _available_actions = state.available_actions()\n",
    "            _random_action = random.choice(_available_actions)\n",
    "            state = state.play_action(_random_action)\n",
    "        return state.get_reward()\n",
    "\n",
    "    # Based on a simulation policy, we continue playing from the expansion node until a terminal node is reached\n",
    "    # select unvisited child nodes\n",
    "    def simulate(self):\n",
    "        _node  = self.select_unvisited_nodes(self.root)\n",
    "        _Q = self.rollout_policy(_node.state)\n",
    "        self.backpropagate(node=_node, _Q = _Q)\n",
    "\n",
    "\n",
    "\n",
    "    def select_unvisited_nodes(self, node : Node):\n",
    "        while node.is_end_state ==False:\n",
    "            if node.is_expanded_completly == True:\n",
    "                node = self.pick_child(node, self.c)\n",
    "            else:\n",
    "                #expanding node\n",
    "                return self.expand(node)\n",
    "        return node\n",
    "\n",
    "    def traverse(self, start_node):\n",
    "        self.root = Node(start_node, None)\n",
    "        tme = time.time() + 2\n",
    "        while time.time() < tme:\n",
    "            self.simulate()\n",
    "\n",
    "        bestChilds = self.pick_child(self.root, c = 0)\n",
    "        action=(action for action, node in self.root.children.items() if node is bestChilds).__next__()\n",
    "        return action\n",
    "\n",
    "    def expand(self,node):\n",
    "        actions = node.state.available_actions()\n",
    "        for action in actions:\n",
    "            if action not in node.children:\n",
    "                new_node = Node(node.state.play_action(action), node)\n",
    "                node.children[action] = new_node\n",
    "                if len(actions) == len(node.children):\n",
    "                    node.is_expanded_completly = True\n",
    "                return new_node\n",
    "\n",
    "\n",
    "    def calculate_value(self,node,child,c):\n",
    "         return node.state.player * ( child.Q / child.N ) + c * np.sqrt(  np.log(node.N) / child.N )        \n",
    "\n",
    "    def calculate_values(self, node, c):\n",
    "        max_value = - math.inf\n",
    "        good_options = []\n",
    "        for child in node.children.values():\n",
    "            uct =self.calculate_value(node,child,c)\n",
    "            if uct > max_value:\n",
    "                max_value = uct\n",
    "                good_options = [child]\n",
    "            elif uct == max_value:\n",
    "                good_options.append(child)\n",
    "        return good_options\n",
    "    \n",
    "    def pick_child(self, node, c):\n",
    "        return random.choice(self.calculate_values(node, c))\n",
    "\n",
    "    # update\n",
    "    def backpropagate(self,node : Node, _Q):\n",
    "        while node is not None:\n",
    "            node.N += 1\n",
    "            node.Q += _Q\n",
    "            node = node.parent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Action():\n",
    "    def __init__(self, player, x, y):\n",
    "        self.player = player\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    ## Just add to remove hash error\n",
    "    def __str__(self):\n",
    "        return str((self.x, self.y))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self.__class__ == other.__class__ and self.x == other.x and self.y == other.y and self.player == other.player\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash((self.x, self.y, self.player))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from functools import reduce\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tic_Tac_Toe():\n",
    "    def __init__(self, size=3):\n",
    "        self.size = size\n",
    "        self.board = (np.zeros((size, size))).tolist()\n",
    "        self.player = 1  \n",
    "\n",
    "    def available_actions(self):\n",
    "        actions = []\n",
    "        for i in range(self.size):\n",
    "            for j in range(self.size):\n",
    "                if self.board[i][j] == 0:\n",
    "                    actions.append(Action(self.player, x=i, y=j))\n",
    "        return actions\n",
    "    \n",
    "    def play_action(self, action : Action):\n",
    "        new_state = deepcopy(self)\n",
    "        new_state.board[action.x][action.y] = action.player\n",
    "        new_state.player = self.player * -1\n",
    "        return new_state\n",
    "    \n",
    "    # Terminal nodes\n",
    "    def is_end_state(self):\n",
    "        # first chekc row\n",
    "        for row in self.board:\n",
    "            if abs(sum(row)) == self.size:\n",
    "                return True\n",
    "        # second check column\n",
    "        for column in np.transpose(self.board):\n",
    "            if abs(sum(column)) == self.size:\n",
    "                return True\n",
    "        # check for diagonals\n",
    "        if abs(sum(np.diag(self.board))) == self.size or abs(sum(np.diag(np.rot90(self.board)))) == self.size:\n",
    "            return True\n",
    "\n",
    "        return reduce(operator.mul, sum(self.board, []), 1)\n",
    "    \n",
    "    def print_board(self):\n",
    "        for i in self.board:\n",
    "            for j in i:\n",
    "                if j == -1: print(Fore.GREEN + 'O' + Style.RESET_ALL, end='\\t') # for first player\n",
    "                elif j == 1: print(Fore.BLUE + 'X' + Style.RESET_ALL, end='\\t') # for second playe\n",
    "                else: print('-', end='\\t')\n",
    "            print(\"\")\n",
    "        print('____________________________\\n')\n",
    "\n",
    "    # -1 for O and 1 for X\n",
    "    def get_reward(self):\n",
    "        for row in self.board:\n",
    "            if abs(sum(row)) == self.size:\n",
    "                return sum(row) / self.size\n",
    "        for column in list(map(list, zip(*self.board))):\n",
    "            if abs(sum(column)) == self.size:\n",
    "                return sum(column) / self.size\n",
    "        for diagonal in [[self.board[i][i] for i in range(len(self.board))], [self.board[i][len(self.board) - i - 1] for i in range(len(self.board))]]:\n",
    "            if abs(sum(diagonal)) == self.size:\n",
    "                return sum(diagonal) / self.size\n",
    "        return False\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AIvsAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X --> (1, 1)\n",
      "\n",
      "-\t-\t-\t\n",
      "-\t\u001b[34mX\u001b[0m\t-\t\n",
      "-\t-\t-\t\n",
      "____________________________\n",
      "\n",
      "O --> (2, 0) \n",
      "\n",
      "-\t-\t-\t\n",
      "-\t\u001b[34mX\u001b[0m\t-\t\n",
      "\u001b[32mO\u001b[0m\t-\t-\t\n",
      "____________________________\n",
      "\n",
      "X --> (2, 1)\n",
      "\n",
      "-\t-\t-\t\n",
      "-\t\u001b[34mX\u001b[0m\t-\t\n",
      "\u001b[32mO\u001b[0m\t\u001b[34mX\u001b[0m\t-\t\n",
      "____________________________\n",
      "\n",
      "O --> (0, 1) \n",
      "\n",
      "-\t\u001b[32mO\u001b[0m\t-\t\n",
      "-\t\u001b[34mX\u001b[0m\t-\t\n",
      "\u001b[32mO\u001b[0m\t\u001b[34mX\u001b[0m\t-\t\n",
      "____________________________\n",
      "\n",
      "X --> (1, 0)\n",
      "\n",
      "-\t\u001b[32mO\u001b[0m\t-\t\n",
      "\u001b[34mX\u001b[0m\t\u001b[34mX\u001b[0m\t-\t\n",
      "\u001b[32mO\u001b[0m\t\u001b[34mX\u001b[0m\t-\t\n",
      "____________________________\n",
      "\n",
      "O --> (1, 2) \n",
      "\n",
      "-\t\u001b[32mO\u001b[0m\t-\t\n",
      "\u001b[34mX\u001b[0m\t\u001b[34mX\u001b[0m\t\u001b[32mO\u001b[0m\t\n",
      "\u001b[32mO\u001b[0m\t\u001b[34mX\u001b[0m\t-\t\n",
      "____________________________\n",
      "\n",
      "X --> (0, 0)\n",
      "\n",
      "\u001b[34mX\u001b[0m\t\u001b[32mO\u001b[0m\t-\t\n",
      "\u001b[34mX\u001b[0m\t\u001b[34mX\u001b[0m\t\u001b[32mO\u001b[0m\t\n",
      "\u001b[32mO\u001b[0m\t\u001b[34mX\u001b[0m\t-\t\n",
      "____________________________\n",
      "\n",
      "O --> (2, 2) \n",
      "\n",
      "\u001b[34mX\u001b[0m\t\u001b[32mO\u001b[0m\t-\t\n",
      "\u001b[34mX\u001b[0m\t\u001b[34mX\u001b[0m\t\u001b[32mO\u001b[0m\t\n",
      "\u001b[32mO\u001b[0m\t\u001b[34mX\u001b[0m\t\u001b[32mO\u001b[0m\t\n",
      "____________________________\n",
      "\n",
      "X --> (0, 2)\n",
      "\n",
      "\u001b[34mX\u001b[0m\t\u001b[32mO\u001b[0m\t\u001b[34mX\u001b[0m\t\n",
      "\u001b[34mX\u001b[0m\t\u001b[34mX\u001b[0m\t\u001b[32mO\u001b[0m\t\n",
      "\u001b[32mO\u001b[0m\t\u001b[34mX\u001b[0m\t\u001b[32mO\u001b[0m\t\n",
      "____________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mcts = monte_carlo_tree_search(c = 0.8 )\n",
    "game = Tic_Tac_Toe()\n",
    "while game.is_end_state() == False:\n",
    "    action = mcts.traverse(start_node=game)\n",
    "    if game.player == 1:\n",
    "      print(\"X --> \"+str(action) + \"\\n\")\n",
    "    else:\n",
    "      print(\"O --> \"+str(action) +\" \\n\")\n",
    "    game = game.play_action(action)\n",
    "    game.print_board()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Human VS AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (human) -> (0, 2) \n",
      "\n",
      "-\t-\tX\t\n",
      "-\t-\t-\t\n",
      "-\t-\t-\t\n",
      "____________________________\n",
      "\n",
      "O (AI) ->  (1, 1) \n",
      "\n",
      "-\t-\tX\t\n",
      "-\tO\t-\t\n",
      "-\t-\t-\t\n",
      "____________________________\n",
      "\n",
      "X (human) -> (1, 2) \n",
      "\n",
      "-\t-\tX\t\n",
      "-\tO\tX\t\n",
      "-\t-\t-\t\n",
      "____________________________\n",
      "\n",
      "O (AI) ->  (2, 2) \n",
      "\n",
      "-\t-\tX\t\n",
      "-\tO\tX\t\n",
      "-\t-\tO\t\n",
      "____________________________\n",
      "\n",
      "X (human) -> (2, 1) \n",
      "\n",
      "-\t-\tX\t\n",
      "-\tO\tX\t\n",
      "-\tX\tO\t\n",
      "____________________________\n",
      "\n",
      "O (AI) ->  (0, 0) \n",
      "\n",
      "O\t-\tX\t\n",
      "-\tO\tX\t\n",
      "-\tX\tO\t\n",
      "____________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mcts = monte_carlo_tree_search(c=0.8)\n",
    "game = Tic_Tac_Toe()\n",
    "flag_turn = 'x'\n",
    "\n",
    "while game.is_end_state() == False:\n",
    "    if flag_turn == 'x':\n",
    "        turn = 1\n",
    "        while turn == 1:\n",
    "            x, y = input(\n",
    "                'Enter your move \"row,column\": ').split(',')\n",
    "            x, y = int(x), int(y)\n",
    "            validActions = game.available_actions()\n",
    "            action = Action(1, x, y)\n",
    "            print(\"X (human) --> \"+ str(action) + \"\\n\" )\n",
    "            game = game.play_action(action)\n",
    "            game.print_board()\n",
    "            flag_turn = 'o'\n",
    "            turn = 2\n",
    "    else:\n",
    "        action = mcts.traverse(start_node=game)\n",
    "        print(\"O (AI) --> \"+str(action)+\" \\n\" )\n",
    "        game = game.play_action(action)\n",
    "        game.print_board()\n",
    "        flag_turn = 'x'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5x5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI --> (4, 4) \n",
      "\n",
      "-\t-\t-\t-\t-\t\n",
      "-\t-\t-\t-\t-\t\n",
      "-\t-\t-\t-\t-\t\n",
      "-\t-\t-\t-\t-\t\n",
      "-\t-\t-\t-\t\u001b[34mX\u001b[0m\t\n",
      "____________________________\n",
      "\n",
      "Human --> (0, 0) \n",
      "\n",
      "\u001b[32mO\u001b[0m\t-\t-\t-\t-\t\n",
      "-\t-\t-\t-\t-\t\n",
      "-\t-\t-\t-\t-\t\n",
      "-\t-\t-\t-\t-\t\n",
      "-\t-\t-\t-\t\u001b[34mX\u001b[0m\t\n",
      "____________________________\n",
      "\n",
      "AI --> (2, 3) \n",
      "\n",
      "\u001b[32mO\u001b[0m\t-\t-\t-\t-\t\n",
      "-\t-\t-\t-\t-\t\n",
      "-\t-\t-\t\u001b[34mX\u001b[0m\t-\t\n",
      "-\t-\t-\t-\t-\t\n",
      "-\t-\t-\t-\t\u001b[34mX\u001b[0m\t\n",
      "____________________________\n",
      "\n",
      "Human --> (0, 1) \n",
      "\n",
      "\u001b[32mO\u001b[0m\t\u001b[32mO\u001b[0m\t-\t-\t-\t\n",
      "-\t-\t-\t-\t-\t\n",
      "-\t-\t-\t\u001b[34mX\u001b[0m\t-\t\n",
      "-\t-\t-\t-\t-\t\n",
      "-\t-\t-\t-\t\u001b[34mX\u001b[0m\t\n",
      "____________________________\n",
      "\n",
      "AI --> (4, 2) \n",
      "\n",
      "\u001b[32mO\u001b[0m\t\u001b[32mO\u001b[0m\t-\t-\t-\t\n",
      "-\t-\t-\t-\t-\t\n",
      "-\t-\t-\t\u001b[34mX\u001b[0m\t-\t\n",
      "-\t-\t-\t-\t-\t\n",
      "-\t-\t\u001b[34mX\u001b[0m\t-\t\u001b[34mX\u001b[0m\t\n",
      "____________________________\n",
      "\n",
      "Human --> (2, 2) \n",
      "\n",
      "\u001b[32mO\u001b[0m\t\u001b[32mO\u001b[0m\t-\t-\t-\t\n",
      "-\t-\t-\t-\t-\t\n",
      "-\t-\t\u001b[32mO\u001b[0m\t\u001b[34mX\u001b[0m\t-\t\n",
      "-\t-\t-\t-\t-\t\n",
      "-\t-\t\u001b[34mX\u001b[0m\t-\t\u001b[34mX\u001b[0m\t\n",
      "____________________________\n",
      "\n",
      "AI --> (4, 0) \n",
      "\n",
      "\u001b[32mO\u001b[0m\t\u001b[32mO\u001b[0m\t-\t-\t-\t\n",
      "-\t-\t-\t-\t-\t\n",
      "-\t-\t\u001b[32mO\u001b[0m\t\u001b[34mX\u001b[0m\t-\t\n",
      "-\t-\t-\t-\t-\t\n",
      "\u001b[34mX\u001b[0m\t-\t\u001b[34mX\u001b[0m\t-\t\u001b[34mX\u001b[0m\t\n",
      "____________________________\n",
      "\n",
      "Human --> (0, 3) \n",
      "\n",
      "\u001b[32mO\u001b[0m\t\u001b[32mO\u001b[0m\t-\t\u001b[32mO\u001b[0m\t-\t\n",
      "-\t-\t-\t-\t-\t\n",
      "-\t-\t\u001b[32mO\u001b[0m\t\u001b[34mX\u001b[0m\t-\t\n",
      "-\t-\t-\t-\t-\t\n",
      "\u001b[34mX\u001b[0m\t-\t\u001b[34mX\u001b[0m\t-\t\u001b[34mX\u001b[0m\t\n",
      "____________________________\n",
      "\n",
      "AI --> (4, 1) \n",
      "\n",
      "\u001b[32mO\u001b[0m\t\u001b[32mO\u001b[0m\t-\t\u001b[32mO\u001b[0m\t-\t\n",
      "-\t-\t-\t-\t-\t\n",
      "-\t-\t\u001b[32mO\u001b[0m\t\u001b[34mX\u001b[0m\t-\t\n",
      "-\t-\t-\t-\t-\t\n",
      "\u001b[34mX\u001b[0m\t\u001b[34mX\u001b[0m\t\u001b[34mX\u001b[0m\t-\t\u001b[34mX\u001b[0m\t\n",
      "____________________________\n",
      "\n",
      "Human --> (1, 0) \n",
      "\n",
      "\u001b[32mO\u001b[0m\t\u001b[32mO\u001b[0m\t-\t\u001b[32mO\u001b[0m\t-\t\n",
      "\u001b[32mO\u001b[0m\t-\t-\t-\t-\t\n",
      "-\t-\t\u001b[32mO\u001b[0m\t\u001b[34mX\u001b[0m\t-\t\n",
      "-\t-\t-\t-\t-\t\n",
      "\u001b[34mX\u001b[0m\t\u001b[34mX\u001b[0m\t\u001b[34mX\u001b[0m\t-\t\u001b[34mX\u001b[0m\t\n",
      "____________________________\n",
      "\n",
      "AI --> (4, 3) \n",
      "\n",
      "\u001b[32mO\u001b[0m\t\u001b[32mO\u001b[0m\t-\t\u001b[32mO\u001b[0m\t-\t\n",
      "\u001b[32mO\u001b[0m\t-\t-\t-\t-\t\n",
      "-\t-\t\u001b[32mO\u001b[0m\t\u001b[34mX\u001b[0m\t-\t\n",
      "-\t-\t-\t-\t-\t\n",
      "\u001b[34mX\u001b[0m\t\u001b[34mX\u001b[0m\t\u001b[34mX\u001b[0m\t\u001b[34mX\u001b[0m\t\u001b[34mX\u001b[0m\t\n",
      "____________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mcts = monte_carlo_tree_search(c=1)\n",
    "game = Tic_Tac_Toe(size=5)\n",
    "flag = 'O'\n",
    "while game.is_end_state() == False:\n",
    "\n",
    "    if flag == 'x':\n",
    "        turn = 1\n",
    "        while turn == 1:\n",
    "            x, y = input(\n",
    "                'Human Enter your move \"row,column\": ').split(',')\n",
    "            x, y = int(x), int(y)\n",
    "            validActions = game.available_actions()\n",
    "            action = Action(-1, x, y)\n",
    "\n",
    "            print(\"Human --> \"+str(action)+\" \\n\")\n",
    "            game = game.play_action(action)\n",
    "            game.print_board()\n",
    "            flag = 'o'\n",
    "            turn = 2\n",
    "\n",
    "    else:\n",
    "        action = mcts.traverse(start_node=game)\n",
    "        print(\"AI --> \"+str(action)+\" \\n\")\n",
    "        game = game.play_action(action)\n",
    "        game.print_board()\n",
    "        flag = 'x'\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
